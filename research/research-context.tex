% report research context

\section{Introduction}
% Research group: IDEAS
% Tool: Ask- Elle
% Focus: research question 2 and 3: easily adding and fine tuning exercises by a 
% tutor 
% Corresponding requirements:
%  - The tutor should be able to create an exercise (...)
%  - Code Layout definition
%  - Programming guidelines definition

The starting point of the 
\gls{examiner} project is pragmatic rather then scientific. 
The urge to reduce labor intensity while maintaining or even improving the 
extent of providing \gls{feedback} has little scientific value by itself. From 
this perspective, it may be argued there is no scientific context, or at least 
no computer science related scientific context. This does by no means degrade 
the scientific value of this project, it just denotes the research context is 
to be found elsewhere. 


The domain research has a practical focus for the greatest part. The 
importance of this approach is clear, when keeping the goal (a functioning 
prototype of the \gls{examiner}) in mind. Whereas the Design Recipe and 
Feedback papers are merely focused on some aspects of the domain, the 
Semantics paper reveals a more fundamental question. In order to get beyond 
the checking of rudimentary characteristics (like functionality, format and 
syntax) it is necessary to reason on \gls{js}, or even on programming 
languages in general, itself. Of course, it is way beyond our limits to pursue 
this reasoning to its foundations. Luckily, this is no unexplored domain.


The main stakeholder of this project directed us towards the IDEAS framework, 
% reference
which is the core for a set of \glspl{domainreasoner}. After broadly studying 
\citep{gerdes2012ask} and \citep{heeren2010specifying} their approaches (with 
regards to semantic analysis) revealed some possible relevant pointers. The 
IDEAS framework is used to generate feedback on input from a specified domain. 
The domain may vary, as the first article is about \gls{haskell}, whereas the 
second is about rewriting strategies for logic expressions.


Both articles describe research projects that focus, like our project, on
providing feedback for (academic) students. In particular, the former article
strengthens the relevance, by putting the usability and maintainability for 
tutors as its central research question. Thus, the goals to our project are 
very much alike. 


When considering their approach, there is one fundamental difference. The IDEAS
framework is designed to provide stepwise feedback. Instead of reviewing a
submitted solution as being complete, it is possible to review a partial 
solution. This feature is deliberately no part of our project. Still, it is 
not unthinkable that there might be successive projects to extend the \gls{
examiner} with this feature. Like our approach, the developed domain reasoners 
are built as prototypes at first. In order to be able to provide feedback on partial solutions, a thoughtful and sophisticated reasoning on the domain specific language semantics is required.


We found Heeren, B. willing to discuss with us some aspects of the IDEAS 
project. Since our project has been presented as being the start of a new and 
autonomous project, the scope and aim for the consult has been fairly general. 
We are primarily interested in the conceptual considerations and scientific 
foundations (in particular on semantic evaluation) rather than focused on the 
pure technical specifications. Eventually, this interest led to an, from our 
experience, interesting and fruitful consult. 


In what follows, the consult will be described. As will become apparent, some 
interesting topics will pass. As a result, a brief examination of one of these 
topics will follow. In conclusion, the consult and examination will be linked 
to our project. Furthermore, some interesting topics will be hinted for 
possible succeeding projects.


\section{Consult}
Due to the nature of our project, the outline and boundaries of this consult 
were not clear beforehand. To prevent a lack of scope, we determined two 
central topics, namely semantic evaluation and the usability of the reasoners 
from a tutor perspective. The meeting with Heeren was very open and fluent. We 
did not strictly follow the order of our prepared questions during the 
conversation. Still, at times the 
conversation spirited away, we used the question to get back to the main 
topic. Since we did not literally recorded the consult, the resume below is an 
interpretation based on the prepared questions, the consult itself and the 
keynotes taken.

%Formative - Summative
After a short introduction on the IDEAS framework and our project, the 
discussion started with a demarcation posted by Heeren, in putting the 
Formative approach of the IDEAS related projects against the Summative 
approach of our project. This distinction is the result of the difference in 
approach. The extent to which our project really is summative, is withheld by 
the way it will be used eventually. %Work out argument 
Still, it seems to be fruitful to keep this distinction alive for now, as the 
central point (no partial solution feedback functionality in our project) is 
striking. 

\subsection{Semantic Evaluation} %Please review this subtitle 
At this point, the conversation shifted to the topic of semantic evaluation.
Heeren introduced to us an overview of the technique to bring code back to a
normal form. This technique abstracts from the particular code, by replacing 
constructs. For example, a \em{for loop} can be replaced by a 
\em{while construct}, without 
changing the execution result of the code. In this way, two solutions can be
compared, even if the first uses the \em{while} construct, and the second a 
\em{for loop}. At first, this seems very fruitful to use, but Heeren made clear
that the search for a normal form is quite hard. Reasoning toward a normal form
is reasoning about equality. Under what conditions can be stated that two or 
more statements are equal. \"A deceitful problem\", according to Heeren. To 
get more insight in the complexity of this topic, an article about one of the
IDEAS based reasoners was recommended to us. \citep{keuning2014strategy} 
stresses the equality problem by reviewing her implementation (and in
doing this the framework as a whole) to the exhaustive set of normalization 
techniques under the name of \gls{spv}. This set, as argued in 
\citep{xu2003transformation}, covers a complete spectrum of normalizing 
techniques on a semantic level. These articles could be the appropriate 
starting point if one wants to add semantic evaluation to the \gls{examiner}.


After this theoretical introduction, some practical pointers were given, that
could be helpful as well, when starting to experiment within this area. 
Thorough analysis of (generation of) \glspl{abs} might discern opportunities 
to get rid of some variations, and as such provide a first implementation of
normalization. %Maybe refer to next chapter 
Furthermore, diving into techniques that deal with static comparison or static
testing might be fruitful, as there is (semantic) reasoning required as well.
Finally, the inverted use of plagiarism detectors could be interesting. 
Inverted use, because the detectors are designed to deal with input that is
ought to be different from eachother (the input to be tested is reviewed 
against all existing documents), whereas we expect and search for similarities to, for example, match a solution with (one of the) example solutions. 


Packed with both a theoretical introduction as practical handlebars on
Semantic Evaluation, the topic changed to our second general question.

\subsection{Create an exercise}
The answer to our main question concerning this topic was clear. At this moment
there are no results from usage of the examiners by tutors that did not
actively participate in the development of the reasoners. Looking at the 
complexity and theoretical approach, this seems reasonable. Still, it stresses
the ability to determine the value of the approach, when comparing it to our 
own project, as our success heavily depends on the usability by the tutors. 
Apart from the lack of test results, Heeren did outline a possible time
consuming factor for tutors. As it is hard or even impossible to normalize 
algorithmic variation, and the diversity in usage of algorithms tends to
grow when the size of an exercise and solutions extends, the only way of 
dealing with this diversity is adding more model solutions (which implements
different algorithms). %May be add example (Quicksort vs Bubblesort oid)
As the space of possible variation grows, the need
for model solutions grows, with a factor tending to exponential. This can 
quite quickly stress of reducing the tutors labor intensity, which is one 
of our main goals. Therefor, it's quite important to keep this goal in mind
when developing the examiner, as new features might have unwanted implications 
to the time and efforts required to successfully deploy the \gls{examiner} or
new \gls{exercises}.

\subsection{Implentation Pointers}
During the consult, we recognized Heeren had gained a lot of experience in the
execution of the research. To learn from him, we conclued the consult by 
asking him what pointers we should take in mind while developing the 
\gls{examiner}. According to him, we should adapt an approach which allows for 
easy expanding and adapting. As our project might be only a first step in a
series of \gls{examiner} related projects, this characteristic is of great 
importance. He advised us to develop service based or at least in a modular 
way. On top of this, he pointed to the importance of relevant test data. It
could be a pitfall to only use or own written exercises and solutions, because
it's not unlikely that solutions from other students are fundamentally 
different when it comes to the means of properly analyzing and reviewing.

\subsection{Resume}
Enthusiastic and enlightened, we thanked Heeren for his help and contribution.
While reviewing the consult, we recognized our flaw in understanding the 
problems related to semantic equality and \gls{spv} more deeply. Even if we 
don't implement related functionality during this project, it's still required
to grasp the fundamentals in order to be able to design and develop an 
appropriate foundation to actually implement functionality related to semantic
evaluation. As a result, a brief analysis of the \gls{spv} is added. 

\section{Semantic Preserving Variations}

% Toetsen aan Javascript in het algemeen

% ????? In hoeverre dit uitwerken ????? Vraag voor Annemiek. ????? Met name 
% gezien het praktische uitgangspunt van Harry en Sylvia.


% From Xu and Chee, explained with the application of IDEAS based reasoner 
% Hieke Keuning
% 1 	Different algorithms
% 2 	Different source code formats
% 3 	Different syntax forms
% 4 	Different variable declarations
% 5 	Different algebraic expression forms 6 Different control structures
% 7 	Different Boolean expression forms 8 Different temporary variables
% 9 	Different redundant statements
% 10 	Different statement orders
% 11 	Different variable names
% 12 	Different program logical structures 
% 13 	Different statements

% Examples:
% SPV1 - Different algorithms (i.e. sorting)
% 	SPV2 - Code format (spaces, indentation, comments)
% 	SPV3 - Syntax forms (if(i) {x = y} else{x = z} or x = (i) ? y : z)
% 	SPV4 - Variable declaration (method / block)
% 	SPV5 - Algebraic expression forms (+ vs --)
% 	SPV6 - Control structures (branching, iterating, traversing)
% 	SPV7 - Boolean expression forms (x == false vs !x (SPV3))
% 	SPV8 - Temporary variables
% 	SPV9 - Redundancy / Code for debugging
% 	SPV10 - Different (statement) order
% 	SPV11 - Diferenent variable names (parameters, functions)
% 	SPV12 - Different logical structures
% 	SPV13 - Different statements

% three forms of representation:

% 	1 - Source Code
% 	2 - AST
% 	3 - Augmented Object-oriented program dependence graph (AOPDG)

% Source-to-specification approach:
% 	-Consistent with Research on program understanding
% 	-Match student code with templates with corresponding specifications OR
% 	-Match student code with specifications like:
% 		*structures
% 		*schemata
% 		*plans
% 		*assertions
% 		*processes
% 	-Moeilijk generaliseren voor alle typen programmeertalen

% Specification-to-specification approach:
% 	-Derive formal specifications from student and reference code
% 	-Not possible for many languages

% Source-to-Source approach:
% 	-performs automatic reasoning at the level of program dependence graphs
% 		(FDG: semantic representation for programs, but no formal specification)

% The Xu and Chee approach:
% 	-Model programs are used as input to the diagnosis of student programs. 
% 	-Comparing student program with model program after standardization 
% (by program transformations)
% 	-transformation-based diagnosis
% 	-Simpler to make use of in practice

% 	-Program standardization and semantic-level program matching
% 	-No intentional checks
	% -Intraprocedural diagnosis method (class hierarchies and inter-procedural 
	% variations are not included)
% 	-Different model programs used to diagnose students program
% 	-correct = being equivalent after standardization
% 	-semantic differences indicate errors

% 	-Computational Semantics vs Operational Semantics


% 	-Standardize programs (representation)
% 	-Match them



 %  Program transformations:

 %  	Basic: (SPV3,4,5,6,7)

 %  	-Statement separation	(remove cascaded messages i.e. var a, b, c = 5);
 %  	-Temporary declaration standardization (declaratie variabelen op bepaalde plaats);
 %  	-Algebraic expression standardization (rules voor notatie berekeningen (normaalvorm));
 %  	-Controle structure standardization (??);
 %  	-Boolean expression standardization (rules voor notatie boolean expressies !x --> x == false);


 %  	Adv:

 %  	-Forward substitution
 %  	-Dead code removal

 %  	3 criteria:

 %  	-Applicable to programs at source code level
 %  	-Covergant (avoid cyclic triggering)
 %  	-Intra-procedural (as limited to intra-procedural)



 %  AOFFG (AUGMENTED Object-Oriented Flow Graph) Program Respresentation

	% -PRG: Program Representation Graphs (Static compile-time semantics) (OFG: Object-oriented Flow Graph for OO)
	% 	*SSA: Static-Single-Assignment
	% 	*PDG: Program Dependence Graphs
	% 		*CDS: Control Dependence Subgraph
	% 		*DDS: Data Dependence Subgraph
	% 	*OPDG: Object-oriented PDG
	%		*PDG
	% 		*ODS: Object Dependence Subgraph
	% 		*ODG: Object based dependence graph		
	% 		*
	% 
	% 	*AOPDG (Augmented Object-oriented Program Dependence Graph) = AOCDS (Augmented Object-oriented Control Dependence Subgraphs) + AODDS (Augmented Object-oriented Data Dependence Subgraphs)(contstructed from AOCDS)
	%  	
	% 	
	% 
	% 	

% Program comparison

	% Partitioned graphs: if vertexSP and vertextMP in same set: statement in vertices semantically equivalent
	% 3 result maps: equivalent map, textual difference map, unmatched map
	% 

% Error detection

	% Problem: Operational semantic differences rather than computational semantic differences
		% --> solution: variation learning process to detect unsystematic semantics-preserving variations
	
\section{Conclusion}

% Mogelijkheden SPV
% In hoeverre wenselijk voor dit project? Wat karakteriseerd JavaScript, en waar is het juist ook niet geschikt voor.... (rapid development vs rigourous analysis (functional math foundational programs)) 
% Handvat voor mogelijke vervolg applicatie.

% In hoeverre tools voorhanden (Uglify )