% verslag analyse onderzoekcontext, plusminus 5 pagina's

\section{Introduction}
% Research group: IDEAS
% Tool: Ask- Elle
% Focus: research question 2 and 3: easily adding and finetuning exercises by a tutor 
% Corresponding requirements:
%  - The tutor should be able to create an exercise (...)
%  - Code Layout definition
%  - Programming guidelines definition

%Questions
%  - Is it possible to get insight in the actual process of exercise creation?
%  - How many exercises have been created by tutors? 
%  - How is their reception of the exercise creation process? (research already in progress?)
%     * What are the difficulties they experience?
%     * Are their didactic aspects they can't, but would like to introduce? 
%     * What features are used most? (i.e. Global vs Location specific)
%  - What were the arguments to work with model solutions? Have other possibilities
%    been considered? (i.e. test suites)
%  - Is there a limit for the magnitude of an exericse? What are implications (towards possibilities, scope etc.)?
%  - Would it be possible to create a set of exercises in a way there is no need for additional material?
%  ? Are there indicators for a tutor on which constructs feedback annotations are needed? How does
%    the retrieve these indicators?
%  - Is there a size limit or minimum for a  provided set of model solutions?
%  - The correctness is based on equality. Is the current measure method to determine (in)equality rightly balanced?
%  - Is it possible to get a demo on actually adding a simple exercise?
%  - Is Ask-Elle flexible in usage? (mainly in the way exercises are added)
%  - How to proceed if there are 3 model solutions,
%    and two solutions need feedback on the same particular construct,
%    should this feedack annotation be global?
%  - How does Ask-Elle make a distinction between the different solutions (from optimal to suboptimal)?
%    @TODO: meer specifieke vragen (met name hoofdstuk 7 + hoofstuk 5 (feedback scripts))
%  - How are the feedback texts generated?
%    And how do you choose which feedback to show
%    according to the step a student took.
%  - Could the normalization rules be easily ported to JavaScript?
%  - Could the Haskell service be modified to be used for JavaScript code?
%  - Or could the functionality of the Haskell service be ported to JavaScript?
%  - How dificult is it for a tutor
%    to provide the right annotations to a model solution?
%  - Could the annotations used by Ask-Elle be used in the same way
%    for a non-functional language (e.g. JavaScript)?

