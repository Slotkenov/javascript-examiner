\section{Introduction} 

Our goal is to make life easier for a tutor
of the \gls{js} programming language.
In our bachelor project we will develop a \gls{examiner}
which will relieve the \gls{tutor} from checking
all \glspl{student}' \glspl{solution} to \glspl{exercise}
and give them appropriate feedback in an online course.
At the same time, the \gls{examiner} will benefit the \glspl{student} as well.
The \gls{tutor} simply doesn't have time
to check the \glspl{solution} of all the \glspl{student}.
And therefore the \gls{tutor} cannot give individual \gls{feedback}
to each \gls{student}.
The \gls{tutor} will pick the biggest and most common pitfalls he sees
in the \glspl{solution} he picks.
Then he will give the \glspl{student} general feedback on those pitfalls
in the next online group session.

The reason why the \gls{examiner} will benefit \glspl{student} --- besides
relieving the \gls{tutor} of too much of a workload --- is threefold.
First off the \gls{examiner} is able
to check all the \glspl{exercise} of all \glspl{student}.
Secondly, the \gls{examiner} can give the \glspl{student}
immediate \gls{feedback} on their \gls{exercise} ---
instead of them having to wait for
the next online group session with the \gls{tutor}.
And finally the \gls{examiner} gives the \gls{student}
individual \gls{feedback}.
Instead of some general explanation
about common pitfalls the \gls{student} might not even have had trouble with,
the \gls{examiner} gives each \gls{student} \gls{feedback}
on the specific problems encountered in his or her \gls{solution}.

This article will be an analysis of the quality aspects of \gls{js-code}
on which the \gls{examiner} can focus.
What kind of quality aspects exist for programming languages in general?
To make sure the scope of this article won't get to wide
I will only pick a few quality aspects.
I will base my choise on what we have learned at the Open University
and on well documented quality aspects found in literature.

How easy is it to measure those quality aspects for a given \gls{code}?
and how precise is the \gls{feedback} of those measurements?
For measuring quality aspects
I will look at literature about available measurements,
how well they are documented
and how dificult it would be to implement such a measurement.
For the availability of \glspl{tool} which can perform such measurements
I would refer to the domain research of
Ronald Kluft\footnote{domain-research-modules.pdf}.
The results of the measurements of different quality aspects can vary from
a general idea about the quality aspect of a given \gls{code}
to more specific indication of how a \gls{code} might be improved.
I will compare the measurements found in this article
on the impact of their results.
More on how \gls{feedback} is givin to the student
can be read in the domain research of
Bram Nieuwenhuize\footnote{domain-research-feedback.pdf}

\section{Code quality}

\Gls{code-quality} can be divided into two areas.
In one area you look at the quality of the \gls{code} itself,
without executing it.
You look at aspects like how the \gls{code} is laid out,
how easy it is to read the \gls{code}
and how well you can understand what the \gls{code} is trying to do.
These aspects have no effect on the execution of the \gls{code} however.
The second area looks at the quality of execution. How well
does the \gls{code} execute? Does it use efficient glspl{construct}?

We will start in this section by looking at the first area:
the quality of the \gls{code}.
First we will see how we can determine the quality of the \gls{code}
by looking at its layout.
Secondly we examine metrics for expressing the \gls{maintainability}
of a given \gls{code} and how we can use that
to give \gls{feedback} to \glspl{student}.

\subsection{Natural Language}

Allthough a programming language is an artificial language,
natural language is also used often in code in the form of
names (of variables, routines, etc.),
headers (documentation blocks above routines, classes, etc.)
and comments (explenation of the code between lines).
These are three important aspects for giving \gls{feedback}
as explained by \citet{stegeman2014empirically}.


\subsection{Code layout}

For readability it is important to structure your code in a way
that conveys clearly the intention of the code.
There are many different ways you could layout your code
and there is not one layout that is better than all the others.
Most important is consistency.

The easiest way to check for a consistent layout would be
if one particular layout would be required from the students.
Then the \gls{examiner} can simply check for that layout.
Otherwise it would have to determine the layout of a particular \gls{exercise}
on various aspects and see if that layout is used
consistently throughout the entire assignment.

Besides being consistent in using one layout
there are still layout aspects that would be considered bad practice
and should be avoided at all times.
There are many \glspl{tool} for examining \gls{code}
to make sure none of these bad practices are used in \gls{code}.
Even specific for \gls{js-code} such \glspl{tool} already
exist.\footnote{For instance JSLint (\url{http://www.jslint.com/})
and the less strict variant JSHint (\url{http://www.jshint.com/})}

\subsubsection{Stegeman}

\paragraph{Names}
Natural language
Maybe spell checking

\paragraph{Headers}
Natural language
JSDoc
Spell checking

\paragraph{Comments}
Natural language
Spell checking
Only where strictly needed

\paragraph{Layout}
Not applicable to small exercises
Unreachable code detection
Detection of commented-out code

\paragraph{Formatting}
Highlight intended structure using
indentation, blank lines, spacing and brackets.
Highlighting similarities and differences between code
by using consistent formatting.
Line length

\paragraph{Flow}
Choosing appropriate language constructs
Not too deep nesting
One task per line
Not too much code in the body of a conditional statement.

\paragraph{Expressions}
Simple expressions
Duplication of (partial) expressions
Unnamed constants

\paragraph{Decomposition}
Limited set of tasks per routine
Limited set of shared variables
Not reuse variables for multiple purposes

\paragraph{Modularization}
Not applicable to small exercises

\subsection{Maintainability}

Various metrics can be used to give an idea
about the \gls{maintainability} of \gls{code}.
We are not looking for measuring \gls{maintainability} specifically,
but an indication of it can help us determine the quality of the \gls{code},
for \gls{maintainability} is an aspect of good quality \gls{code}.
\citet{rakic2013problems} list the following metrics
used in tools for analyzing \gls{code}:
\begin{itemize}
  \item Lines of code;
  \item Cyclomatic complexity;
  \item Halstead complexity;
  \item Object oriented metrics.
\end{itemize}
We will look at the first three metrics mentioned. The last one --- Object
oriented metrics --- might also be an interesting metric when object oriented
aspects are introduced in the \glspl{exercise}.
But it would lead too far for this research to go into;
it can be the subject of a later research.

First off you can look at the amount of \gls{code}
in terms of lines of \gls{code}.
The more lines of \gls{code}, the more complex it gets.
There are different ways to determine the lines of \gls{code} though.
You can simply count all the lines in the source files,
which we will call lines of code (LOC).
But you could also skip the lines which contain comments and empty lines,
the remaining lines we will call source lines of code (SLOC).
Going one step further you can count the actual statements in the \gls{code}
instead of the physical lines.
That will give you the logical lines of code (LLOC).
A disadvantage of LLOC is that it is more difficult to calculate.
Instead of simply counting the lines of a text file.
You would need serious knowledge of the programming language in question.

Only looking at the lines of \gls{code} is not very useful.
We can compare the LOC of the \gls{student}
with the \gls{solution} of the \gls{tutor},
but that will give you only a rough idea about
whether the \gls{student} used far too much \gls{code} or extraordinarily few.

A more precise measurement of the complexity of code
might be cyclomatic complexity.
This basically tells you in how many unique paths
your \gls{code} could be executed \citep{website:js-complexity}.
When the cyclomatic complexity increases,
so does the complexity of your \gls{code}.
The more possible execution paths,
the more difficult it is to reason about your \gls{code}.
But because the cyclomatic complexity increases
when the code base increases
it is more useful to express the cyclomatic complexity relative to
the lines of \gls{code}.
This gives us the cyclomatic complexity density \citep{gill1991cyclomatic}.

The third metric we will be discussing is the Halstead complexity
which looks at operators and its operands.
It determines the amount of operators and operands in a given \gls{code}.
It also determines the amount of distinct operators and operands.
With that data some calculations are performed
to determine the complexity of the \gls{code}.

While it is not necessary to fully understand
the programming language for performing the Halstead metric,
that method has some shortcomings as explained by \citet{yu2010survey}.
Where the cyclomatic complexity looks at the control flow of the code,
the Halstead methed only looks at the operations performed,
but ignores the control flow completely.
When used together however you can look at you \gls{code} from both sides
and express the \gls{maintainability} in a combination of the results.

\section{Execution quality}

The quality of a given \gls{code} can be determined by looking at
the \glspl{construct} that have been used,
and by looking at the manner in which the \glspl{construct} have been combined.

There is an interesting way to look at a new programming language
which can also help us here to look at \gls{js-code},
of what structures it is composed and how they are combined.
These words from Abelson and
Sussman\footnote{Abelson, H., Sussman, G.J. 1984
  {\em Structure and Interpretation of Computer Programs}.
  MIT Press, [\url{https://mitpress.mit.edu/sicp/}]}
give us that way of thinking:
``What are the primitives, what are their means of combination,
and what are their means of abstraction?''

To follow these words we would first have to look at
the \glspl{construct} of \gls{js}.
Then we can determine in what ways these \glspl{construct} can be combined.
Finally we could look at the means of abstraction \gls{js} offers us,
but unfortunately there is not enough time
to handle that aspect in this research.

\subsection{Relative execution time}

The \gls{rel-exe-time} of a given \gls{code} can be measured mathematically.
As explained by \citet[Chapter 4]{goodrich2008data}
the \gls{rel-exe-time} can be expressed using seven functions
(constant, logarithm, linear, n-log~n, etc.).
To determine with which function
the gls{rel-exe-time} of a given \gls{code} can be expressed
one has to look at the \glspl{construct} used in that \gls{code}.
For each \gls{construct} the \gls{rel-exe-time} has to be determined.
Then you can calculate the \gls{rel-exe-time}
of the combination of those functions
(i.e.\ the combination of the \glspl{construct} that make op the \gls{code}).

This method would be a good way to see
if the \gls{student} has used an algorithm
that is too complex for the given \gls{exercise}.
If, for example, the \gls{solution} of the \gls{tutor} executes in n-log~n time
while the \gls{code} of the \gls{student} executes in quadratic time,
\gls{feedback} could be given to the \gls{student}
that he should use a more efficient algorithm for that \gls{exercise}.
The question would be:
how to give the \gls{student} more concrete \gls{feedback}?
Instead of just telling him he can do better
it would be constructive to point him in the right direction.
However, this would require more knowledge of the particular \gls{exercise}
and the difference between the \gls{solution} of the \gls{tutor}
and the \gls{solution} of the \gls{student}.

An implementation of this method would require more than
determining the \glspl{construct} used in a given \gls{code}
and how they are combined.
When a loop is used, for instance,
you would need information about run time variables
to determine how many times the loop would be iterated over.
In other words: looking at the \glspl{construct} is not enough,
you would need a good understanding of the algorithm used
and the problem that is being solved.
This understanding might be provided
by letting the \gls{tutor} specify information about the algorithm used
when creating an \gls{exercise} in the \gls{examiner}.
However further study will be required to figure out
how this would best be implemented,
and what information would be required exactly from the \gls{tutor}.

\subsection{Language constructs}

When looking at the meaning of the code you can distinguish different language
constructs. When you look at an exercise, it might be the case that a good
solution should contain one or two specific language constructs. That means
that we can look for those structures in a student's code. If they are not
there, or if there are too much of them, the student can be given feedback
mentioning this fact. In order to be able to give the student a more profound
explanation of why his code is not optimal we would need input from the
tutor. Because our goal is to relieve the tutor from too much work we could try
and implement this feature in a similar way \citet[Section
3.2]{watson2011learning} proposed in their article. They describe a way to
provide feedback on how to correct a given code that generates an error
(halting on execution). The
first time the system encounters a specific error it has to request the tutor
for feedback. The system saves that feedback into a database along with the
error. On any subsequent occurrence of that same error in any of the students'
code the system retrieves the tutor's feedback from the database. It does not
need to bother the tutor any more, while the student receives valuable
feedback.

We would need to determine first what language constructs are important
for a specific exercise.
When a student uses a for loop where the tutor does not,
that would be an interesting case.
But when a student uses one more simple assignment statement than the
tutor does, that will probably not be very important for instance. We can
determine the set of language constructs used in the code, by type and by
quantity. And compare that with the solution of the tutor. This gives us a set
of language constructs the student did not use while the tutor did, and a set
of language constructs of the other way around. After filtering these two sets
of language constructs for important ones we have something to give feedback
on. Now we can use the same mechanics as \citet{watson2011learning}
described. We look in the database for the feedback on a particular language
construct that was used --- or not used --- and show that to the student. In
case no feedback was found in the database, the tutor is requested for input.
In that case the student will not receive immediate feedback.
But after the tutor has provided feedback to the system
all other students who run into the same problem
will receive the feedback immediately.

Interesting use of this method for later implementation can be the comparison
--- not only of the a student's solution with the teacher's solution --- of a
student's code with the code of previously submitted code of other
students. This might give the student feedback on how he is doing relative to
his fellow students.

Research would be needed to see if this would work the way I describe it
here. Would it be feasible to determine how to rate the language constructs of
the JavaScript language? And would the system find all the problem cases or
will it miss some, or find cases that are of no importance?  Besides that, this
functionality would have to be created from the ground up because it is quite
specific and I have not found something like it for JavaScript.

\section{Comparing code}

The code layout is an absolute check to see if the student's code adheres to a
well defined set of rules of best practices in coding. The code either fails on
some points or it is completely laid out according to the layout definitions
used. How you go about giving feedback when some rules are broken is another
question. The JavaScript-examiner could say the code is incorrect or more
gently tell the student that it could be better. It could clearly point out
where the shortcomings are or simply tell the student to do better. The point
is that the rules of code layout can be well defined, how strict you hold the
student to it is a matter of feedback.

A different matter are the other metrics for code and execution quality. They
do not simply give you an answer whether the code is good or not. It is more of
a gray area and you would need to determine when code is good, when it is
acceptable and when it would need improvement. These acceptability margins will
be different for each exercise (e.g.\ a more complex assignment should allow a
higher cyclomatic complexity). The tutor could be asked to specify these
margins when creating an exercise, but the tutor might struggle to determine
good margins for the exercise at hand.

The great thing is: we do not need to determine the quality of a given code
on its own. We can compare it to a well defined base code that is assumed to be
correct and efficient (i.e.\ an acceptable solution),
by asking the tutor to write a solution to the exercise himself.
the JavaScript-examiner could determine a baseline for the different metrics
by calculating the metrics for the tutor's solution.
That means that we do not
need to decide how many lines of code would be too much, or what cyclomatic
complexity would make the code too complex. We can just compare the lines of
code, and the Halstead complexity of a student's code with the solution of the
tutor.
That way the system would have a good base for which it can say:
when I get these results (or better results) for the metrics on a given
code, the code is good, otherwise the code could be better. Preferably you
would still want some form of margin, where the results of the metrics only
slightly below those of the tutor's are as acceptable as the
tutor's. Determining how those margins can best be calculated is subject to
further research.
We do have to determine however: how bad is the code if it is not as
good as the solution of the tutor? There should probably be some margin of
acceptance.


\section{Conclusion}

While no one method is perfect it would be best to combine several methods to
determine the quality of the code and of its execution. Looking at code layout
is a good starting point and will be easy to implement because many tools exist
for performing these checks for JavaScript code. The other methods will require
a baseline which can be obtained by analyzing the tutor's solution. This won't
be a problem to implement as well but would require further research and
development for determining the right margins of acceptance of these metrics.

The maintainability metrics are well defined and have been implemented in
different tools. Therefore these are also a good candidate to implement in
the JavaScript-examiner. Some extra research might be necessary though to find
the right implementation, use and combination of these metrics for best
representing the quality of the students' code.

Examining execution quality of a given code would be an interesting area to
look into, but will take more time and effort to implement. To calculate the
gls{rel-exe-time}, good understanding of the code and the algorithm are
needed. Also --- because of its complexity --- no ready to be used tools exist
for executing this specific method. Serious research and development will be
needed to be able to implement it.

Building up a database with specific usages of code constructs for an exercise
along with helpful feedback for a student seems an interesting solution. The
JavaScript-examiner will be able to generate valuable feedback, simply and
effectively by asking the tutor. At the same time the teacher will be relieved
from too much work because the system would save that feedback into a
database. Further research is needed to determine the best way of extracting
the important language constructs from code. Development is needed to implement
this functionality and make sure the feedback from the database will be
supplied at the right times.

